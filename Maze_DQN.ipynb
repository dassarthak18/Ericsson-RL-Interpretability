{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c630db7a",
   "metadata": {},
   "source": [
    "# Dynamically generated m by n grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dd7c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 20:16:24.946501: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:24.946575: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747f179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:\n",
      "G * 0 X 0 \n",
      "0 0 * 0 * \n",
      "0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "from SimpleMaze import SimpleMaze\n",
    "env = SimpleMaze(3,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6097c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Complex Neural Network for DQN, SARSA\n",
    "CD_model = Sequential()\n",
    "CD_model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "CD_model.add(Dense(16))\n",
    "CD_model.add(Activation('relu'))\n",
    "CD_model.add(Dense(16))\n",
    "CD_model.add(Activation('relu'))\n",
    "CD_model.add(Dense(16))\n",
    "CD_model.add(Activation('relu'))\n",
    "CD_model.add(Dense(nb_actions))\n",
    "CD_model.add(Activation('linear'))\n",
    "\n",
    "# Boltzmann Q Policy\n",
    "BQ_policy = BoltzmannQPolicy()\n",
    "\n",
    "# Sequential Memory\n",
    "S_memory = SequentialMemory(limit=50000, window_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8243ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 20:16:35.271498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 20:16:35.272126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272555: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272655: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-04 20:16:35.272895: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-04 20:16:35.273344: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "   76/10000 [..............................] - ETA: 13s - reward: -0.8684 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 96s 10ms/step - reward: -0.6990\n",
      "338 episodes - episode_reward: -20.672 [-1873.000, 35.000] - loss: 11.775 - mse: 87.420 - mean_q: -8.890\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 99s 10ms/step - reward: -0.2694\n",
      "497 episodes - episode_reward: -5.394 [-766.000, 37.000] - loss: 11.749 - mse: 10.597 - mean_q: -0.346\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 102s 10ms/step - reward: -0.0842\n",
      "522 episodes - episode_reward: -1.648 [-357.000, 37.000] - loss: 10.212 - mse: 10.189 - mean_q: 3.490\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 106s 11ms/step - reward: 0.1238\n",
      "562 episodes - episode_reward: 2.196 [-501.000, 41.000] - loss: 9.516 - mse: 19.171 - mean_q: 5.396\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 109s 11ms/step - reward: 0.1824\n",
      "done, took 513.160 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5cf1f82970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = DQNAgent(model=CD_model, nb_actions=nb_actions, memory=S_memory, nb_steps_warmup=100, target_model_update=1e-2, policy=BQ_policy)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mse'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1f46da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 * \n",
      "G 0 0 0 * \n",
      "S X 0 0 * \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 * \n",
      "G 0 0 0 * \n",
      "S 0 X 0 * \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 * \n",
      "G 0 0 0 * \n",
      "S 0 0 X * \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 * \n",
      "G 0 0 0 * \n",
      "S 0 0 0 X \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 0 0 0 * \n",
      "G 0 0 0 X \n",
      "S 0 0 0 0 \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 0 0 0 X \n",
      "G 0 0 0 0 \n",
      "S 0 0 0 0 \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 0 X 0 \n",
      "G 0 0 0 0 \n",
      "S 0 0 0 0 \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 X 0 0 \n",
      "G 0 0 0 0 \n",
      "S 0 0 0 0 \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 X 0 0 0 \n",
      "G 0 0 0 0 \n",
      "S 0 0 0 0 \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "X 0 0 0 0 \n",
      "G 0 0 0 0 \n",
      "S 0 0 0 0 \n",
      "\n",
      "Next action:Move down\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "X 0 0 0 0 \n",
      "S 0 0 0 0 \n",
      "Episode 1: reward: 19.000, steps: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5cf167ad30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=1, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ce309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:\n",
      "0 0 0 * 0 \n",
      "0 * 0 0 G \n",
      "* 0 0 X 0 \n"
     ]
    }
   ],
   "source": [
    "env2 = SimpleMaze(3,5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc99f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Neural Network for DQN, SARSA\n",
    "CD_model2 = Sequential()\n",
    "CD_model2.add(Flatten(input_shape=(1,) + env2.observation_space.shape))\n",
    "CD_model2.add(Dense(16))\n",
    "CD_model2.add(Activation('relu'))\n",
    "CD_model2.add(Dense(16))\n",
    "CD_model2.add(Activation('relu'))\n",
    "CD_model2.add(Dense(16))\n",
    "CD_model2.add(Activation('relu'))\n",
    "CD_model2.add(Dense(nb_actions))\n",
    "CD_model2.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c552fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 110s 11ms/step - reward: -0.6228\n",
      "388 episodes - episode_reward: -16.049 [-1025.000, 35.000] - loss: 10.604 - mse: 21.590 - mean_q: 5.161\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 114s 11ms/step - reward: -0.6552\n",
      "417 episodes - episode_reward: -15.741 [-841.000, 37.000] - loss: 9.442 - mse: 25.963 - mean_q: 6.307\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 106s 11ms/step - reward: -0.7738\n",
      "381 episodes - episode_reward: -18.824 [-620.000, 37.000] - loss: 10.653 - mse: 12.976 - mean_q: 3.929\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 106s 11ms/step - reward: -0.3978\n",
      "407 episodes - episode_reward: -10.978 [-770.000, 37.000] - loss: 12.108 - mse: 6.853 - mean_q: 1.098\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 112s 11ms/step - reward: -0.7822\n",
      "done, took 548.262 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ca1626e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn2 = DQNAgent(model=CD_model2, nb_actions=nb_actions, memory=S_memory, nb_steps_warmup=100, target_model_update=1e-2, policy=BQ_policy)\n",
    "dqn2.compile(Adam(learning_rate=1e-3), metrics=['mse'])\n",
    "dqn2.fit(env2, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6e4dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "\n",
      "Next action:Move down\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * X \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "* 0 G 0 X \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 0 0 0 X \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 0 X 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 X 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 X 0 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 X 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 X 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 X 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 X 0 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "X 0 0 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "X 0 0 0 0 \n",
      "* 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move down\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "X 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 X G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "X 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 X G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 X 0 0 0 \n",
      "0 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move down\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 X G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "X 0 G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 X G 0 0 \n",
      "0 * 0 * S \n",
      "\n",
      "Next action:Move down\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 0 G 0 0 \n",
      "0 X 0 * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 0 G 0 0 \n",
      "0 0 X * S \n",
      "\n",
      "Next action:Move right\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 0 G 0 0 \n",
      "0 0 0 X S \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 0 G X 0 \n",
      "0 0 0 0 S \n",
      "\n",
      "Next action:Move up\n",
      "Map:\n",
      "0 0 0 X 0 \n",
      "0 0 G 0 0 \n",
      "0 0 0 0 S \n",
      "\n",
      "Next action:Move down\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 0 G X 0 \n",
      "0 0 0 0 S \n",
      "\n",
      "Next action:Move left\n",
      "Map:\n",
      "0 0 0 0 0 \n",
      "0 0 X 0 0 \n",
      "0 0 0 0 S \n",
      "Episode 1: reward: 7.000, steps: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ca17f4c40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn2.test(env2, nb_episodes=1, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
