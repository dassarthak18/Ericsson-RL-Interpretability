{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7dd7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from src import algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191863ca",
   "metadata": {},
   "source": [
    "## SimpleMaze_v0 DQN (Epsilon-Greedy Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6468a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:\n",
      "0 0 0 0 \n",
      "* X 0 * \n",
      "0 G * 0 \n",
      "0 * 0 0 \n",
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "   47/10000 [..............................] - ETA: 10s - reward: -1.9574  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 105s 11ms/step - reward: 1.6893\n",
      "1131 episodes - episode_reward: 14.915 [-966.000, 30.000] - loss: 0.452 - mse: 80.894 - mean_q: 6.795\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 106s 11ms/step - reward: 2.4517\n",
      "1161 episodes - episode_reward: 21.124 [-118.000, 30.000] - loss: 0.304 - mse: 109.816 - mean_q: 11.817\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 104s 10ms/step - reward: 1.8409\n",
      "864 episodes - episode_reward: 21.325 [-330.000, 30.000] - loss: 0.477 - mse: 125.841 - mean_q: 12.358\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 110s 11ms/step - reward: 2.4800\n",
      "986 episodes - episode_reward: 25.143 [-299.000, 30.000] - loss: 0.504 - mse: 137.964 - mean_q: 12.948\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 113s 11ms/step - reward: 2.3690\n",
      "done, took 537.786 seconds\n",
      "INFO:tensorflow:Assets written to: models/SimpleMaze_v0_DQN_Eps_50000/assets\n"
     ]
    }
   ],
   "source": [
    "from env.SimpleMaze_v0 import SimpleMaze\n",
    "env = SimpleMaze(True)\n",
    "model, agent, train_rewards = algo.dqn(env)\n",
    "model.save(\"models/SimpleMaze_v0_DQN_Eps_50000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660c616",
   "metadata": {},
   "source": [
    "## SimpleMaze_v1 DQN (Epsilon-Greedy Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4daa609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:\n",
      "0 0 0 * \n",
      "0 * 0 0 \n",
      "G 0 * 0 \n",
      "0 X 0 * \n",
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 106s 11ms/step - reward: -1.3004\n",
      "297 episodes - episode_reward: -43.680 [-1019.000, 52.000] - loss: 8.719 - mse: 654.463 - mean_q: -24.026\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 111s 11ms/step - reward: -1.2156\n",
      "364 episodes - episode_reward: -29.657 [-2438.000, 54.000] - loss: 17.239 - mse: 954.275 - mean_q: -29.808\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 115s 12ms/step - reward: -0.7184\n",
      "521 episodes - episode_reward: -16.445 [-1987.000, 55.000] - loss: 17.983 - mse: 823.085 - mean_q: -27.236\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 117s 12ms/step - reward: -0.5394\n",
      "460 episodes - episode_reward: -11.713 [-504.000, 53.000] - loss: 18.218 - mse: 656.603 - mean_q: -23.623\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 120s 12ms/step - reward: -0.5070\n",
      "done, took 570.374 seconds\n",
      "INFO:tensorflow:Assets written to: models/SimpleMaze_v1_DQN_Eps_50000/assets\n"
     ]
    }
   ],
   "source": [
    "from env.SimpleMaze_v1 import SimpleMaze\n",
    "env = SimpleMaze(4,4,True)\n",
    "model, agent, train_rewards = algo.dqn(env)\n",
    "model.save(\"models/SimpleMaze_v1_DQN_Eps_50000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f91bfe",
   "metadata": {},
   "source": [
    "## CartPole-v1 DQN (Epsilon-Greedy Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a50c64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "   41/10000 [..............................] - ETA: 12s - reward: 1.0000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 104s 10ms/step - reward: 1.0000\n",
      "105 episodes - episode_reward: 94.514 [9.000, 235.000] - loss: 1.258 - mse: 798.311 - mean_q: 35.024\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 106s 11ms/step - reward: 1.0000\n",
      "54 episodes - episode_reward: 183.667 [15.000, 401.000] - loss: 2.547 - mse: 2514.995 - mean_q: 67.145\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 105s 11ms/step - reward: 1.0000\n",
      "35 episodes - episode_reward: 288.286 [162.000, 500.000] - loss: 4.587 - mse: 3272.027 - mean_q: 78.168\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 119s 12ms/step - reward: 1.0000\n",
      "31 episodes - episode_reward: 319.613 [162.000, 500.000] - loss: 4.117 - mse: 4256.138 - mean_q: 88.931\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 119s 12ms/step - reward: 1.0000\n",
      "done, took 552.835 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:12:52.275044: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CartPole_v1_DQN_Eps_50000/assets\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "model, agent, train_rewards = algo.dqn(env)\n",
    "model.save(\"models/CartPole_v1_DQN_Eps_50000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
